# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# PEP 582; used by e.g. github.com/David-OConnor/pyflow
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

import pandas as pd
import numpy as np
import seaborn as sns 
import matplotlib.pyplot as plt
import statsmodels as smp
import scipy.stats as stats
import pylab

rename_columns = {'JURISDICTION_CODE':'LOCATION_JURISDICTION_CODE', 
    'JURISDICTION_DESCRIPTION':'LOCATION_JURISDICTION_DESCRIPTION', 
    'ASK_FOR_CONSENT_FLG':'ASK_FOR_CONSENT_FLAG', 
    'CONSENT_GIVEN_FLG':'CONSENT_GIVEN_FLAG'}
#importing file and formating columns to numerical
stops2020 = pd.read_excel('sqf-2020.xlsx').rename(columns = rename_columns)

#Normaling nulls. Lots of '' instead null
stops2020 = stops2020.replace(to_replace='(null)',value='NA')
stops2020 = stops2020.replace(to_replace=np.nan,value='NA')


#find groups patthern
variables_pattherns = ['LOCATION', 'PHYSICAL', 'SUSPECT', 'OFFICER', 'SEARCH', 'FLAG']
agged_variables, columns_to_drop = {}, []
for patthern in variables_pattherns:
    agged_variables[patthern] = stops2020.columns[stops2020.columns.str.contains(patthern)].tolist()
    globals()[f'stops2020_{patthern}'] = stops2020[agged_variables[patthern]]
    columns_to_drop += agged_variables[patthern]
    print(str(f'stops2020_{patthern}'))
    
stops20_r_pat = stops2020.drop(columns=columns_to_drop)
#Creating groups of variables 
for group in agged_variables:
    lst_col = agged_variables[group]
    for col in lst_col:
        print(stops2020[col].value_counts())
        
plt.hist(stops2020[agged_variables['LOCATION'][-1]], bins = 5)

arrested = stops2020[stops2020[agged_variables['SUSPECT'][1]]=='Y']
arrested.groupby(by='STOP_LOCATION_BORO_NAME')[agged_variables['SUSPECT'][15]].value_counts() / arrested.shape[0]

#vs

stops2020.groupby(by='STOP_LOCATION_BORO_NAME')[agged_variables['SUSPECT'][15]].value_counts() / stops2020.shape[0]

#Arrested ratio over stops by Location
stops2020.groupby(by='STOP_LOCATION_BORO_NAME')[agged_variables['SUSPECT'][1]].value_counts()
